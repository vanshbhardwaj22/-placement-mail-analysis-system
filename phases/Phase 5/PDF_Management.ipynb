{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95ff8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# PHASE 5C: PDF INTEGRATION & MANAGEMENT SYSTEM\n",
    "# Complete PDF handling for job attachments\n",
    "# ===================================================================\n",
    "# Purpose: Link PDFs to jobs, extract text, summarize, and manage\n",
    "# Dependencies: PyPDF2, google-generativeai, pandas\n",
    "# ===================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Any, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "# ===================================================================\n",
    "# LOGGING CONFIGURATION\n",
    "# ===================================================================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"pdf_manager.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(\"PDFManager\")\n",
    "\n",
    "# ===================================================================\n",
    "# PDF METADATA STRUCTURE\n",
    "# ===================================================================\n",
    "\n",
    "@dataclass\n",
    "class PDFMetadata:\n",
    "    \"\"\"\n",
    "    Metadata for a PDF attachment.\n",
    "    Links PDF files to job postings.\n",
    "    \"\"\"\n",
    "    pdf_id: str\n",
    "    file_path: str\n",
    "    file_name: str\n",
    "    file_size: int  # in bytes\n",
    "    job_id: Optional[str] = None\n",
    "    message_id: Optional[str] = None\n",
    "    email_subject: Optional[str] = None\n",
    "    page_count: int = 0\n",
    "    text_extracted: bool = False\n",
    "    summary_generated: bool = False\n",
    "    created_at: str = field(default_factory=lambda: datetime.now().isoformat())\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary.\"\"\"\n",
    "        return {\n",
    "            'pdf_id': self.pdf_id,\n",
    "            'file_path': self.file_path,\n",
    "            'file_name': self.file_name,\n",
    "            'file_size': self.file_size,\n",
    "            'file_size_mb': round(self.file_size / (1024 * 1024), 2),\n",
    "            'job_id': self.job_id,\n",
    "            'message_id': self.message_id,\n",
    "            'email_subject': self.email_subject,\n",
    "            'page_count': self.page_count,\n",
    "            'text_extracted': self.text_extracted,\n",
    "            'summary_generated': self.summary_generated,\n",
    "            'created_at': self.created_at\n",
    "        }\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# PDF TEXT EXTRACTOR\n",
    "# ===================================================================\n",
    "\n",
    "class PDFTextExtractor:\n",
    "    \"\"\"\n",
    "    Extract text content from PDF files.\n",
    "    Handles various PDF formats and encoding issues.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize PDF text extractor.\"\"\"\n",
    "        self.logger = logging.getLogger(\"PDFExtractor\")\n",
    "        \n",
    "        # Try importing PDF libraries\n",
    "        self.pdf_library = None\n",
    "        \n",
    "        # Try PyPDF2 first\n",
    "        try:\n",
    "            import PyPDF2\n",
    "            self.PyPDF2 = PyPDF2\n",
    "            self.pdf_library = \"PyPDF2\"\n",
    "            self.logger.info(\"‚úÖ Using PyPDF2 for PDF extraction\")\n",
    "        except ImportError:\n",
    "            pass\n",
    "        \n",
    "        # Try pdfplumber as alternative\n",
    "        if not self.pdf_library:\n",
    "            try:\n",
    "                import pdfplumber\n",
    "                self.pdfplumber = pdfplumber\n",
    "                self.pdf_library = \"pdfplumber\"\n",
    "                self.logger.info(\"‚úÖ Using pdfplumber for PDF extraction\")\n",
    "            except ImportError:\n",
    "                pass\n",
    "        \n",
    "        if not self.pdf_library:\n",
    "            self.logger.warning(\"‚ö†Ô∏è No PDF library available!\")\n",
    "            self.logger.warning(\"Install with: pip install PyPDF2 or pip install pdfplumber\")\n",
    "    \n",
    "    def extract_text(self, pdf_path: str) -> Tuple[str, int]:\n",
    "        \"\"\"\n",
    "        Extract text from PDF file.\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: Path to PDF file\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (extracted_text, page_count)\n",
    "        \"\"\"\n",
    "        if not self.pdf_library:\n",
    "            self.logger.error(\"‚ùå No PDF library available for extraction\")\n",
    "            return \"\", 0\n",
    "        \n",
    "        try:\n",
    "            if self.pdf_library == \"PyPDF2\":\n",
    "                return self._extract_with_pypdf2(pdf_path)\n",
    "            elif self.pdf_library == \"pdfplumber\":\n",
    "                return self._extract_with_pdfplumber(pdf_path)\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Error extracting text from {pdf_path}: {e}\")\n",
    "            return \"\", 0\n",
    "    \n",
    "    def _extract_with_pypdf2(self, pdf_path: str) -> Tuple[str, int]:\n",
    "        \"\"\"Extract text using PyPDF2.\"\"\"\n",
    "        text_parts = []\n",
    "        page_count = 0\n",
    "        \n",
    "        try:\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                pdf_reader = self.PyPDF2.PdfReader(file)\n",
    "                page_count = len(pdf_reader.pages)\n",
    "                \n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    try:\n",
    "                        text = page.extract_text()\n",
    "                        if text:\n",
    "                            text_parts.append(text)\n",
    "                    except Exception as e:\n",
    "                        self.logger.warning(f\"‚ö†Ô∏è Error on page {page_num}: {e}\")\n",
    "                        continue\n",
    "            \n",
    "            full_text = \"\\n\\n\".join(text_parts)\n",
    "            self.logger.info(f\"‚úÖ Extracted {len(full_text)} chars from {page_count} pages\")\n",
    "            \n",
    "            return full_text, page_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå PyPDF2 extraction failed: {e}\")\n",
    "            return \"\", 0\n",
    "    \n",
    "    def _extract_with_pdfplumber(self, pdf_path: str) -> Tuple[str, int]:\n",
    "        \"\"\"Extract text using pdfplumber.\"\"\"\n",
    "        text_parts = []\n",
    "        page_count = 0\n",
    "        \n",
    "        try:\n",
    "            with self.pdfplumber.open(pdf_path) as pdf:\n",
    "                page_count = len(pdf.pages)\n",
    "                \n",
    "                for page_num, page in enumerate(pdf.pages):\n",
    "                    try:\n",
    "                        text = page.extract_text()\n",
    "                        if text:\n",
    "                            text_parts.append(text)\n",
    "                    except Exception as e:\n",
    "                        self.logger.warning(f\"‚ö†Ô∏è Error on page {page_num}: {e}\")\n",
    "                        continue\n",
    "            \n",
    "            full_text = \"\\n\\n\".join(text_parts)\n",
    "            self.logger.info(f\"‚úÖ Extracted {len(full_text)} chars from {page_count} pages\")\n",
    "            \n",
    "            return full_text, page_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå pdfplumber extraction failed: {e}\")\n",
    "            return \"\", 0\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# PDF SUMMARIZER (using Gemini)\n",
    "# ===================================================================\n",
    "\n",
    "class PDFSummarizer:\n",
    "    \"\"\"\n",
    "    Generate intelligent summaries of PDF content using Gemini.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, gemini_api_key: Optional[str] = None):\n",
    "            \"\"\"\n",
    "            Initialize Gemini Client.\n",
    "            \n",
    "            Args:\n",
    "                gemini_api_key: Gemini API key\n",
    "            \"\"\"\n",
    "            # Use the specific logger name you requested or generic client name\n",
    "            self.logger = logging.getLogger(\"GeminiClient\") \n",
    "            \n",
    "            # Import Gemini\n",
    "            try:\n",
    "                import google.generativeai as genai\n",
    "                self.genai = genai\n",
    "            except ImportError:\n",
    "                self.logger.error(\"‚ùå google-generativeai not installed!\")\n",
    "                raise\n",
    "            \n",
    "            # Get API key from environment variable\n",
    "            self.api_key = gemini_api_key or os.getenv('GEMINI_API_KEY')\n",
    "            if not self.api_key:\n",
    "                self.logger.warning(\"‚ö†Ô∏è No Gemini API key - summaries unavailable\")\n",
    "                self.model = None\n",
    "                return\n",
    "            \n",
    "            # Configure and initialize model\n",
    "            try:\n",
    "                self.genai.configure(api_key=self.api_key)\n",
    "                self.model = self.genai.GenerativeModel('gemini-1.5-flash')\n",
    "                self.logger.info(\"‚úÖ Gemini summarizer initialized\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"‚ùå Failed to initialize Gemini: {e}\")\n",
    "                self.model = None\n",
    "    \n",
    "    def summarize_job_pdf(self, pdf_text: str, max_length: int = 500) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate structured summary of job PDF.\n",
    "        \n",
    "        Args:\n",
    "            pdf_text: Extracted PDF text\n",
    "            max_length: Maximum summary length\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with summary components\n",
    "        \"\"\"\n",
    "        if not self.model:\n",
    "            self.logger.warning(\"‚ö†Ô∏è Summarizer not available\")\n",
    "            return {\n",
    "                'summary': 'Summary unavailable - Gemini not configured',\n",
    "                'key_points': [],\n",
    "                'requirements': [],\n",
    "                'benefits': []\n",
    "            }\n",
    "        \n",
    "        try:\n",
    "            # Truncate text if too long (Gemini has token limits)\n",
    "            text_to_summarize = pdf_text[:15000]  # ~4000 words\n",
    "            \n",
    "            prompt = f\"\"\"Analyze this job description PDF and provide a structured summary.\n",
    "\n",
    "PDF Content:\n",
    "{text_to_summarize}\n",
    "\n",
    "Provide a JSON response with:\n",
    "{{\n",
    "  \"summary\": \"Brief 2-3 sentence overview\",\n",
    "  \"key_points\": [\"Main point 1\", \"Main point 2\", ...],\n",
    "  \"requirements\": [\"Requirement 1\", \"Requirement 2\", ...],\n",
    "  \"benefits\": [\"Benefit 1\", \"Benefit 2\", ...],\n",
    "  \"application_process\": \"How to apply (if mentioned)\"\n",
    "}}\n",
    "\n",
    "Focus on:\n",
    "- Job role and responsibilities\n",
    "- Required skills and qualifications\n",
    "- Salary and benefits (if mentioned)\n",
    "- Application deadline and process\n",
    "- Company culture (if mentioned)\n",
    "\n",
    "Return ONLY valid JSON, no markdown or other text.\"\"\"\n",
    "\n",
    "            response = self.model.generate_content(prompt)\n",
    "            result_text = response.text.strip()\n",
    "            \n",
    "            # Clean JSON (remove markdown if present)\n",
    "            if result_text.startswith('```'):\n",
    "                result_text = result_text.split('```')[1]\n",
    "                if result_text.startswith('json'):\n",
    "                    result_text = result_text[4:]\n",
    "                result_text = result_text.strip()\n",
    "            \n",
    "            # Parse JSON\n",
    "            summary_data = json.loads(result_text)\n",
    "            \n",
    "            self.logger.info(\"‚úÖ PDF summary generated successfully\")\n",
    "            return summary_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Error generating summary: {e}\")\n",
    "            return {\n",
    "                'summary': 'Error generating summary',\n",
    "                'key_points': [],\n",
    "                'requirements': [],\n",
    "                'benefits': []\n",
    "            }\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# PDF MANAGER\n",
    "# ===================================================================\n",
    "\n",
    "class PDFManager:\n",
    "    \"\"\"\n",
    "    Complete PDF management system.\n",
    "    Handles organization, linking, extraction, and retrieval of PDFs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        pdf_directory: str = \"./pdfs\",\n",
    "        metadata_file: str = \"pdf_metadata.json\",\n",
    "        gemini_api_key: Optional[str] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize PDF manager.\n",
    "        \n",
    "        Args:\n",
    "            pdf_directory: Directory containing PDF files\n",
    "            metadata_file: Path to metadata JSON file\n",
    "            gemini_api_key: Gemini API key for summarization\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(\"PDFManager\")\n",
    "        self.pdf_directory = Path(pdf_directory)\n",
    "        self.metadata_file = Path(metadata_file)\n",
    "        \n",
    "        self.logger.info(\"=\"*70)\n",
    "        self.logger.info(\"üìÑ INITIALIZING PDF MANAGER\")\n",
    "        self.logger.info(\"=\"*70)\n",
    "        \n",
    "        # Create PDF directory if not exists\n",
    "        self.pdf_directory.mkdir(exist_ok=True)\n",
    "        self.logger.info(f\"‚úÖ PDF directory: {self.pdf_directory}\")\n",
    "        \n",
    "        # Initialize components\n",
    "        self.extractor = PDFTextExtractor()\n",
    "        self.summarizer = PDFSummarizer(gemini_api_key)\n",
    "        \n",
    "        # Load metadata\n",
    "        self.metadata: Dict[str, PDFMetadata] = {}\n",
    "        self.load_metadata()\n",
    "        \n",
    "        # PDF text cache (in-memory)\n",
    "        self.text_cache: Dict[str, str] = {}\n",
    "        \n",
    "        # PDF summaries cache\n",
    "        self.summary_cache: Dict[str, Dict[str, Any]] = {}\n",
    "        \n",
    "        self.logger.info(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    def load_metadata(self):\n",
    "        \"\"\"Load PDF metadata from JSON file.\"\"\"\n",
    "        if self.metadata_file.exists():\n",
    "            try:\n",
    "                with open(self.metadata_file, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                    for pdf_id, metadata_dict in data.items():\n",
    "                        self.metadata[pdf_id] = PDFMetadata(**metadata_dict)\n",
    "                self.logger.info(f\"‚úÖ Loaded metadata for {len(self.metadata)} PDFs\")\n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"‚ùå Error loading metadata: {e}\")\n",
    "        else:\n",
    "            self.logger.info(\"üìù No existing metadata found - starting fresh\")\n",
    "    \n",
    "    def save_metadata(self):\n",
    "        \"\"\"Save PDF metadata to JSON file.\"\"\"\n",
    "        try:\n",
    "            data = {\n",
    "                pdf_id: metadata.to_dict() \n",
    "                for pdf_id, metadata in self.metadata.items()\n",
    "            }\n",
    "            with open(self.metadata_file, 'w') as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "            self.logger.info(f\"üíæ Saved metadata for {len(self.metadata)} PDFs\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Error saving metadata: {e}\")\n",
    "    \n",
    "    def scan_directory(self) -> List[PDFMetadata]:\n",
    "        \"\"\"\n",
    "        Scan PDF directory and register all PDF files.\n",
    "        \n",
    "        Returns:\n",
    "            List of PDFMetadata objects for new files\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"\\n{'‚îÄ'*70}\")\n",
    "        self.logger.info(\"üîç SCANNING PDF DIRECTORY\")\n",
    "        self.logger.info(f\"{'‚îÄ'*70}\")\n",
    "        \n",
    "        new_pdfs = []\n",
    "        \n",
    "        try:\n",
    "            # Find all PDF files\n",
    "            pdf_files = list(self.pdf_directory.glob(\"**/*.pdf\"))\n",
    "            self.logger.info(f\"üìÇ Found {len(pdf_files)} PDF files\")\n",
    "            \n",
    "            for pdf_path in pdf_files:\n",
    "                # Generate PDF ID from file hash\n",
    "                pdf_id = self._generate_pdf_id(pdf_path)\n",
    "                \n",
    "                # Skip if already registered\n",
    "                if pdf_id in self.metadata:\n",
    "                    continue\n",
    "                \n",
    "                # Get file info\n",
    "                file_stats = pdf_path.stat()\n",
    "                \n",
    "                # Create metadata\n",
    "                metadata = PDFMetadata(\n",
    "                    pdf_id=pdf_id,\n",
    "                    file_path=str(pdf_path),\n",
    "                    file_name=pdf_path.name,\n",
    "                    file_size=file_stats.st_size\n",
    "                )\n",
    "                \n",
    "                self.metadata[pdf_id] = metadata\n",
    "                new_pdfs.append(metadata)\n",
    "                \n",
    "                self.logger.info(f\"  ‚úÖ Registered: {pdf_path.name}\")\n",
    "            \n",
    "            # Save updated metadata\n",
    "            if new_pdfs:\n",
    "                self.save_metadata()\n",
    "                self.logger.info(f\"\\n‚úÖ Registered {len(new_pdfs)} new PDFs\")\n",
    "            else:\n",
    "                self.logger.info(f\"\\n‚úÖ All PDFs already registered\")\n",
    "            \n",
    "            self.logger.info(f\"{'‚îÄ'*70}\\n\")\n",
    "            \n",
    "            return new_pdfs\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Error scanning directory: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def _generate_pdf_id(self, pdf_path: Path) -> str:\n",
    "        \"\"\"Generate unique ID for PDF based on file hash.\"\"\"\n",
    "        try:\n",
    "            # Use file content hash for ID\n",
    "            with open(pdf_path, 'rb') as f:\n",
    "                file_hash = hashlib.md5(f.read()).hexdigest()\n",
    "            return f\"PDF_{file_hash[:12]}\"\n",
    "        except:\n",
    "            # Fallback to filename-based ID\n",
    "            return f\"PDF_{pdf_path.stem}\"\n",
    "    \n",
    "    def link_pdf_to_job(\n",
    "        self,\n",
    "        pdf_id: str,\n",
    "        job_id: str,\n",
    "        message_id: Optional[str] = None,\n",
    "        email_subject: Optional[str] = None\n",
    "    ) -> bool:\n",
    "        \"\"\"\n",
    "        Link a PDF to a job posting.\n",
    "        \n",
    "        Args:\n",
    "            pdf_id: PDF identifier\n",
    "            job_id: Job posting identifier\n",
    "            message_id: Original email message ID\n",
    "            email_subject: Email subject line\n",
    "            \n",
    "        Returns:\n",
    "            True if successful\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if pdf_id not in self.metadata:\n",
    "                self.logger.error(f\"‚ùå PDF {pdf_id} not found\")\n",
    "                return False\n",
    "            \n",
    "            metadata = self.metadata[pdf_id]\n",
    "            metadata.job_id = job_id\n",
    "            metadata.message_id = message_id\n",
    "            metadata.email_subject = email_subject\n",
    "            \n",
    "            self.save_metadata()\n",
    "            self.logger.info(f\"‚úÖ Linked PDF {pdf_id} to job {job_id}\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Error linking PDF: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def extract_pdf_text(self, pdf_id: str, force: bool = False) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract text from PDF.\n",
    "        \n",
    "        Args:\n",
    "            pdf_id: PDF identifier\n",
    "            force: Force re-extraction even if cached\n",
    "            \n",
    "        Returns:\n",
    "            Extracted text or None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check cache first\n",
    "            if not force and pdf_id in self.text_cache:\n",
    "                self.logger.info(f\"üìã Using cached text for {pdf_id}\")\n",
    "                return self.text_cache[pdf_id]\n",
    "            \n",
    "            # Get metadata\n",
    "            if pdf_id not in self.metadata:\n",
    "                self.logger.error(f\"‚ùå PDF {pdf_id} not found\")\n",
    "                return None\n",
    "            \n",
    "            metadata = self.metadata[pdf_id]\n",
    "            \n",
    "            # Extract text\n",
    "            self.logger.info(f\"üìÑ Extracting text from {metadata.file_name}...\")\n",
    "            text, page_count = self.extractor.extract_text(metadata.file_path)\n",
    "            \n",
    "            if text:\n",
    "                # Update metadata\n",
    "                metadata.page_count = page_count\n",
    "                metadata.text_extracted = True\n",
    "                self.save_metadata()\n",
    "                \n",
    "                # Cache text\n",
    "                self.text_cache[pdf_id] = text\n",
    "                \n",
    "                self.logger.info(f\"‚úÖ Extracted {len(text)} characters from {page_count} pages\")\n",
    "                return text\n",
    "            else:\n",
    "                self.logger.warning(f\"‚ö†Ô∏è No text extracted from {metadata.file_name}\")\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Error extracting text: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def generate_pdf_summary(self, pdf_id: str, force: bool = False) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Generate AI summary of PDF content.\n",
    "        \n",
    "        Args:\n",
    "            pdf_id: PDF identifier\n",
    "            force: Force regeneration even if cached\n",
    "            \n",
    "        Returns:\n",
    "            Summary dictionary or None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Check cache\n",
    "            if not force and pdf_id in self.summary_cache:\n",
    "                self.logger.info(f\"üìã Using cached summary for {pdf_id}\")\n",
    "                return self.summary_cache[pdf_id]\n",
    "            \n",
    "            # Extract text if needed\n",
    "            text = self.extract_pdf_text(pdf_id)\n",
    "            if not text:\n",
    "                return None\n",
    "            \n",
    "            # Generate summary\n",
    "            self.logger.info(f\"ü§ñ Generating AI summary for {pdf_id}...\")\n",
    "            summary = self.summarizer.summarize_job_pdf(text)\n",
    "            \n",
    "            if summary:\n",
    "                # Update metadata\n",
    "                if pdf_id in self.metadata:\n",
    "                    self.metadata[pdf_id].summary_generated = True\n",
    "                    self.save_metadata()\n",
    "                \n",
    "                # Cache summary\n",
    "                self.summary_cache[pdf_id] = summary\n",
    "                \n",
    "                self.logger.info(f\"‚úÖ Summary generated successfully\")\n",
    "                return summary\n",
    "            else:\n",
    "                return None\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Error generating summary: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_pdfs_for_job(self, job_id: str) -> List[PDFMetadata]:\n",
    "        \"\"\"\n",
    "        Get all PDFs linked to a job.\n",
    "        \n",
    "        Args:\n",
    "            job_id: Job identifier\n",
    "            \n",
    "        Returns:\n",
    "            List of PDFMetadata objects\n",
    "        \"\"\"\n",
    "        pdfs = [\n",
    "            metadata for metadata in self.metadata.values()\n",
    "            if metadata.job_id == job_id\n",
    "        ]\n",
    "        return pdfs\n",
    "    \n",
    "    def get_pdf_info(self, pdf_id: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Get complete information about a PDF.\n",
    "        \n",
    "        Args:\n",
    "            pdf_id: PDF identifier\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with PDF info\n",
    "        \"\"\"\n",
    "        if pdf_id not in self.metadata:\n",
    "            return None\n",
    "        \n",
    "        metadata = self.metadata[pdf_id]\n",
    "        \n",
    "        info = metadata.to_dict()\n",
    "        \n",
    "        # Add text if available\n",
    "        if pdf_id in self.text_cache:\n",
    "            info['has_text'] = True\n",
    "            info['text_preview'] = self.text_cache[pdf_id][:200] + \"...\"\n",
    "        else:\n",
    "            info['has_text'] = False\n",
    "        \n",
    "        # Add summary if available\n",
    "        if pdf_id in self.summary_cache:\n",
    "            info['has_summary'] = True\n",
    "            info['summary'] = self.summary_cache[pdf_id]\n",
    "        else:\n",
    "            info['has_summary'] = False\n",
    "        \n",
    "        return info\n",
    "    \n",
    "    def process_all_pdfs(self, extract_text: bool = True, generate_summaries: bool = True):\n",
    "        \"\"\"\n",
    "        Process all PDFs in the directory.\n",
    "        \n",
    "        Args:\n",
    "            extract_text: Whether to extract text\n",
    "            generate_summaries: Whether to generate summaries\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"\\n{'='*70}\")\n",
    "        self.logger.info(\"‚öôÔ∏è  PROCESSING ALL PDFs\")\n",
    "        self.logger.info(f\"{'='*70}\\n\")\n",
    "        \n",
    "        total_pdfs = len(self.metadata)\n",
    "        processed = 0\n",
    "        \n",
    "        for pdf_id, metadata in self.metadata.items():\n",
    "            self.logger.info(f\"üìÑ Processing {metadata.file_name}...\")\n",
    "            \n",
    "            try:\n",
    "                # Extract text\n",
    "                if extract_text and not metadata.text_extracted:\n",
    "                    self.extract_pdf_text(pdf_id)\n",
    "                \n",
    "                # Generate summary\n",
    "                if generate_summaries and not metadata.summary_generated:\n",
    "                    self.generate_pdf_summary(pdf_id)\n",
    "                \n",
    "                processed += 1\n",
    "                self.logger.info(f\"‚úÖ Processed {processed}/{total_pdfs}\\n\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(f\"‚ùå Error processing {metadata.file_name}: {e}\\n\")\n",
    "                continue\n",
    "        \n",
    "        self.logger.info(f\"{'='*70}\")\n",
    "        self.logger.info(f\"‚úÖ PROCESSING COMPLETE - {processed}/{total_pdfs} PDFs\")\n",
    "        self.logger.info(f\"{'='*70}\\n\")\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# PDF-JOB LINKER\n",
    "# ===================================================================\n",
    "\n",
    "class PDFJobLinker:\n",
    "    \"\"\"\n",
    "    Automatically link PDFs to jobs based on email MessageId.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        pdf_manager: PDFManager,\n",
    "        emails_csv: str = \"placement_emails.csv\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize PDF-Job linker.\n",
    "        \n",
    "        Args:\n",
    "            pdf_manager: PDFManager instance\n",
    "            emails_csv: Path to emails CSV\n",
    "        \"\"\"\n",
    "        self.pdf_manager = pdf_manager\n",
    "        self.logger = logging.getLogger(\"PDFJobLinker\")\n",
    "        \n",
    "        # Load emails data\n",
    "        try:\n",
    "            self.emails_df = pd.read_csv(emails_csv)\n",
    "            self.logger.info(f\"‚úÖ Loaded {len(self.emails_df)} emails\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Failed to load emails: {e}\")\n",
    "            self.emails_df = pd.DataFrame()\n",
    "    \n",
    "    def auto_link_pdfs(self, jobs_df: pd.DataFrame) -> int:\n",
    "        \"\"\"\n",
    "        Automatically link PDFs to jobs based on MessageId.\n",
    "        \n",
    "        Args:\n",
    "            jobs_df: DataFrame with job postings\n",
    "            \n",
    "        Returns:\n",
    "            Number of PDFs linked\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"\\n{'='*70}\")\n",
    "        self.logger.info(\"üîó AUTO-LINKING PDFs TO JOBS\")\n",
    "        self.logger.info(f\"{'='*70}\\n\")\n",
    "        \n",
    "        linked_count = 0\n",
    "        \n",
    "        try:\n",
    "            # Create MessageId to Job mapping\n",
    "            message_to_job = {}\n",
    "            for _, job in jobs_df.iterrows():\n",
    "                email_id = job.get('email_id', '')\n",
    "                job_id = job.get('job_id', '')\n",
    "                if email_id and job_id:\n",
    "                    message_to_job[email_id] = job_id\n",
    "            \n",
    "            # Match PDFs by filename patterns (assuming format: MessageId_*.pdf)\n",
    "            for pdf_id, metadata in self.pdf_manager.metadata.items():\n",
    "                if metadata.job_id:\n",
    "                    continue  # Already linked\n",
    "                \n",
    "                # Try to extract MessageId from filename\n",
    "                filename = metadata.file_name\n",
    "                \n",
    "                # Common patterns: MSG_123.pdf, message_123_doc.pdf, etc.\n",
    "                for message_id, job_id in message_to_job.items():\n",
    "                    if message_id in filename or filename.startswith(message_id):\n",
    "                        # Get email subject\n",
    "                        email_subject = None\n",
    "                        email_match = self.emails_df[self.emails_df['MessageId'] == message_id]\n",
    "                        if not email_match.empty:\n",
    "                            email_subject = email_match.iloc[0].get('Subject', '')\n",
    "                        \n",
    "                        # Link PDF to job\n",
    "                        success = self.pdf_manager.link_pdf_to_job(\n",
    "                            pdf_id=pdf_id,\n",
    "                            job_id=job_id,\n",
    "                            message_id=message_id,\n",
    "                            email_subject=email_subject\n",
    "                        )\n",
    "                        \n",
    "                        if success:\n",
    "                            linked_count += 1\n",
    "                            self.logger.info(f\"  ‚úÖ Linked {filename} ‚Üí {job_id}\")\n",
    "                        break\n",
    "            \n",
    "            self.logger.info(f\"\\n{'='*70}\")\n",
    "            self.logger.info(f\"‚úÖ LINKING COMPLETE - {linked_count} PDFs linked\")\n",
    "            self.logger.info(f\"{'='*70}\\n\")\n",
    "            \n",
    "            return linked_count\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"‚ùå Error in auto-linking: {e}\")\n",
    "            return linked_count\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# TESTING & EXAMPLES\n",
    "# ===================================================================\n",
    "\n",
    "def test_pdf_system():\n",
    "    \"\"\"Test the PDF management system.\"\"\"\n",
    "    logger.info(\"\\n\" + \"=\"*70)\n",
    "    logger.info(\"üß™ TESTING PDF SYSTEM\")\n",
    "    logger.info(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Initialize PDF manager\n",
    "    pdf_dir = r\"D:\\Projects By Month\\November 2025\\Placement Mail Analysis System\\.venv\\Phase_scripts\\Phase 1\\attachments\"\n",
    "    pdf_manager = PDFManager(\n",
    "        pdf_directory=pdf_dir,\n",
    "        gemini_api_key=os.getenv('GEMINI_API_KEY')\n",
    "    )\n",
    "    \n",
    "    # Scan directory\n",
    "    new_pdfs = pdf_manager.scan_directory()\n",
    "    logger.info(f\"‚úÖ Found {len(pdf_manager.metadata)} total PDFs\")\n",
    "    \n",
    "    # Process one PDF as example\n",
    "    if pdf_manager.metadata:\n",
    "        pdf_id = list(pdf_manager.metadata.keys())[0]\n",
    "        logger.info(f\"\\nüìÑ Testing with PDF: {pdf_id}\")\n",
    "        \n",
    "        # Extract text\n",
    "        text = pdf_manager.extract_pdf_text(pdf_id)\n",
    "        if text:\n",
    "            logger.info(f\"‚úÖ Text extracted: {len(text)} characters\")\n",
    "        \n",
    "        # Generate summary\n",
    "        summary = pdf_manager.generate_pdf_summary(pdf_id)\n",
    "        if summary:\n",
    "            logger.info(f\"‚úÖ Summary generated\")\n",
    "            logger.info(f\"Summary: {summary.get('summary', 'N/A')}\")\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# MAIN EXECUTION\n",
    "# ===================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_pdf_system()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Placement Mail Analysis System",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
