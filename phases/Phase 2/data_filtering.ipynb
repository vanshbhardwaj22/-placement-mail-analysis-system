{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e66caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# DATASET FILTERING PIPELINE\n",
    "# Keep only relevant placement emails with extracted features\n",
    "# ===================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "# ===================================================================\n",
    "# LOGGING SETUP\n",
    "# ===================================================================\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s [%(levelname)s] %(message)s\"\n",
    ")\n",
    "logger = logging.getLogger(\"DatasetFilter\")\n",
    "\n",
    "# ===================================================================\n",
    "# CONFIGURATION\n",
    "# ===================================================================\n",
    "\n",
    "# Columns to keep in final dataset\n",
    "FINAL_COLUMNS = [\n",
    "    'MessageId',\n",
    "    'Sender', \n",
    "    'Subject',\n",
    "    'Date',\n",
    "    'PDFs',\n",
    "    'combined_text',\n",
    "    'cleaned_text',\n",
    "    'processing_status',\n",
    "    'companies_extracted',\n",
    "    'skills_extracted',\n",
    "    'positions_extracted',\n",
    "    'locations_extracted',\n",
    "    'salary_info',\n",
    "    'experience_required',\n",
    "    'degrees_required'\n",
    "]\n",
    "\n",
    "# ===================================================================\n",
    "# FILTERING CRITERIA\n",
    "# ===================================================================\n",
    "\n",
    "def is_relevant_email(row) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if email is relevant based on extracted features.\n",
    "    \n",
    "    An email is relevant if it has:\n",
    "    - At least one company OR\n",
    "    - At least one skill OR\n",
    "    - At least one position OR\n",
    "    - At least one location\n",
    "    \n",
    "    This ensures we only keep placement-related emails.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check if any feature is extracted\n",
    "    has_company = pd.notna(row['companies_extracted']) and row['companies_extracted'].strip() != ''\n",
    "    has_skills = pd.notna(row['skills_extracted']) and row['skills_extracted'].strip() != ''\n",
    "    has_position = pd.notna(row['positions_extracted']) and row['positions_extracted'].strip() != ''\n",
    "    has_location = pd.notna(row['locations_extracted']) and row['locations_extracted'].strip() != ''\n",
    "    has_salary = pd.notna(row['salary_info']) and row['salary_info'].strip() != ''\n",
    "    has_experience = pd.notna(row['experience_required']) and row['experience_required'].strip() != ''\n",
    "    has_degree = pd.notna(row['degrees_required']) and row['degrees_required'].strip() != ''\n",
    "    \n",
    "    # Email is relevant if it has at least 2 features\n",
    "    feature_count = sum([\n",
    "        has_company, \n",
    "        has_skills, \n",
    "        has_position, \n",
    "        has_location,\n",
    "        has_salary,\n",
    "        has_experience,\n",
    "        has_degree\n",
    "    ])\n",
    "    \n",
    "    # Also ensure cleaned text is not empty\n",
    "    has_content = pd.notna(row['cleaned_text']) and len(str(row['cleaned_text']).strip()) > 20\n",
    "    \n",
    "    return feature_count >= 2 and has_content\n",
    "\n",
    "# ===================================================================\n",
    "# MAIN FILTERING FUNCTION\n",
    "# ===================================================================\n",
    "\n",
    "def filter_relevant_emails(\n",
    "    input_csv: str = \"ai_cleaned_emails.csv\",\n",
    "    output_csv: str = \"relevant_placement_emails.csv\"\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filter dataset to keep only relevant placement emails.\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Path to input CSV (output from AI cleaning pipeline)\n",
    "        output_csv: Path to save filtered CSV\n",
    "    \n",
    "    Returns:\n",
    "        Filtered DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(\"=\"*70)\n",
    "    logger.info(\"DATASET FILTERING PIPELINE\")\n",
    "    logger.info(\"=\"*70)\n",
    "    \n",
    "    # Load dataset\n",
    "    logger.info(f\"Loading dataset: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv)\n",
    "    original_count = len(df)\n",
    "    logger.info(f\"Loaded {original_count} emails\")\n",
    "    \n",
    "    # Check which columns exist\n",
    "    logger.info(f\"\\nAvailable columns: {len(df.columns)}\")\n",
    "    existing_columns = df.columns.tolist()\n",
    "    \n",
    "    # Verify required columns exist\n",
    "    missing_columns = [col for col in FINAL_COLUMNS if col not in existing_columns]\n",
    "    if missing_columns:\n",
    "        logger.warning(f\"Missing columns: {missing_columns}\")\n",
    "        logger.info(f\"Available columns: {existing_columns}\")\n",
    "        # Use only available columns\n",
    "        final_columns = [col for col in FINAL_COLUMNS if col in existing_columns]\n",
    "    else:\n",
    "        final_columns = FINAL_COLUMNS\n",
    "    \n",
    "    logger.info(f\"Using {len(final_columns)} columns\")\n",
    "    \n",
    "    # Apply relevance filter\n",
    "    logger.info(f\"\\nApplying relevance filter...\")\n",
    "    logger.info(f\"   Criteria: At least 2 features extracted + meaningful content\")\n",
    "    \n",
    "    df['is_relevant'] = df.apply(is_relevant_email, axis=1)\n",
    "    relevant_df = df[df['is_relevant']].copy()\n",
    "    relevant_count = len(relevant_df)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    filtered_count = original_count - relevant_count\n",
    "    retention_rate = (relevant_count / original_count) * 100\n",
    "    \n",
    "    logger.info(f\"\\nFILTERING RESULTS:\")\n",
    "    logger.info(f\"   Original emails: {original_count}\")\n",
    "    logger.info(f\"   Relevant emails: {relevant_count}\")\n",
    "    logger.info(f\"   Filtered out: {filtered_count}\")\n",
    "    logger.info(f\"   Retention rate: {retention_rate:.1f}%\")\n",
    "    \n",
    "    # Show breakdown by feature\n",
    "    logger.info(f\"\\nFEATURE BREAKDOWN (Relevant Emails Only):\")\n",
    "    \n",
    "    with_companies = relevant_df['companies_extracted'].notna() & (relevant_df['companies_extracted'] != '')\n",
    "    with_skills = relevant_df['skills_extracted'].notna() & (relevant_df['skills_extracted'] != '')\n",
    "    with_positions = relevant_df['positions_extracted'].notna() & (relevant_df['positions_extracted'] != '')\n",
    "    with_locations = relevant_df['locations_extracted'].notna() & (relevant_df['locations_extracted'] != '')\n",
    "    with_salary = relevant_df['salary_info'].notna() & (relevant_df['salary_info'] != '')\n",
    "    with_experience = relevant_df['experience_required'].notna() & (relevant_df['experience_required'] != '')\n",
    "    with_degrees = relevant_df['degrees_required'].notna() & (relevant_df['degrees_required'] != '')\n",
    "    \n",
    "    logger.info(f\"With Companies: {with_companies.sum()} ({with_companies.sum()/relevant_count*100:.1f}%)\")\n",
    "    logger.info(f\"With Skills: {with_skills.sum()} ({with_skills.sum()/relevant_count*100:.1f}%)\")\n",
    "    logger.info(f\"With Positions: {with_positions.sum()} ({with_positions.sum()/relevant_count*100:.1f}%)\")\n",
    "    logger.info(f\"With Locations: {with_locations.sum()} ({with_locations.sum()/relevant_count*100:.1f}%)\")\n",
    "    logger.info(f\"With Salary: {with_salary.sum()} ({with_salary.sum()/relevant_count*100:.1f}%)\")\n",
    "    logger.info(f\"With Experience: {with_experience.sum()} ({with_experience.sum()/relevant_count*100:.1f}%)\")\n",
    "    logger.info(f\"With Degrees: {with_degrees.sum()} ({with_degrees.sum()/relevant_count*100:.1f}%)\")\n",
    "    \n",
    "    # Select only required columns\n",
    "    relevant_df = relevant_df[final_columns].copy()\n",
    "    \n",
    "    # Sort by number of features (most complete emails first)\n",
    "    logger.info(f\"\\nSorting by completeness (most features first)...\")\n",
    "    \n",
    "    relevant_df['feature_score'] = (\n",
    "        relevant_df['companies_extracted'].notna().astype(int) +\n",
    "        relevant_df['skills_extracted'].notna().astype(int) +\n",
    "        relevant_df['positions_extracted'].notna().astype(int) +\n",
    "        relevant_df['locations_extracted'].notna().astype(int) +\n",
    "        relevant_df['salary_info'].notna().astype(int) +\n",
    "        relevant_df['experience_required'].notna().astype(int) +\n",
    "        relevant_df['degrees_required'].notna().astype(int)\n",
    "    )\n",
    "    \n",
    "    relevant_df = relevant_df.sort_values('feature_score', ascending=False)\n",
    "    relevant_df = relevant_df.drop('feature_score', axis=1)\n",
    "    \n",
    "    # Save filtered dataset\n",
    "    logger.info(f\"\\nSaving filtered dataset...\")\n",
    "    relevant_df.to_csv(output_csv, index=False)\n",
    "    logger.info(f\"Saved to: {output_csv}\")\n",
    "    \n",
    "    # Show sample of filtered emails\n",
    "    logger.info(f\"\\nSAMPLE OF TOP 5 RELEVANT EMAILS:\")\n",
    "    logger.info(\"=\"*70)\n",
    "    \n",
    "    for idx, row in relevant_df.head(5).iterrows():\n",
    "        logger.info(f\"\\n--- Email {idx} ---\")\n",
    "        logger.info(f\"Subject: {str(row['Subject'])[:60]}\")\n",
    "        logger.info(f\"Companies: {str(row['companies_extracted'])[:60]}\")\n",
    "        logger.info(f\"Skills: {str(row['skills_extracted'])[:60]}\")\n",
    "        logger.info(f\"Positions: {str(row['positions_extracted'])[:60]}\")\n",
    "        logger.info(f\"Locations: {str(row['locations_extracted'])[:60]}\")\n",
    "    \n",
    "    logger.info(f\"\\n{'='*70}\")\n",
    "    logger.info(f\"FILTERING COMPLETE!\")\n",
    "    logger.info(f\"{'='*70}\")\n",
    "    logger.info(f\"Original file: {input_csv} ({original_count} emails)\")\n",
    "    logger.info(f\"Filtered file: {output_csv} ({relevant_count} emails)\")\n",
    "    logger.info(f\"{'='*70}\\n\")\n",
    "    \n",
    "    return relevant_df\n",
    "\n",
    "# ===================================================================\n",
    "# ADVANCED FILTERING OPTIONS\n",
    "# ===================================================================\n",
    "\n",
    "def filter_by_custom_criteria(\n",
    "    input_csv: str = \"ai_cleaned_emails.csv\",\n",
    "    output_csv: str = \"custom_filtered_emails.csv\",\n",
    "    min_companies: int = 0,\n",
    "    min_skills: int = 1,\n",
    "    min_positions: int = 0,\n",
    "    require_location: bool = False,\n",
    "    require_salary: bool = False,\n",
    "    min_word_count: int = 20\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Custom filtering with specific criteria.\n",
    "    \n",
    "    Args:\n",
    "        input_csv: Input CSV file\n",
    "        output_csv: Output CSV file\n",
    "        min_companies: Minimum number of companies required\n",
    "        min_skills: Minimum number of skills required\n",
    "        min_positions: Minimum number of positions required\n",
    "        require_location: Must have location\n",
    "        require_salary: Must have salary info\n",
    "        min_word_count: Minimum word count in cleaned text\n",
    "    \n",
    "    Returns:\n",
    "        Filtered DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    logger.info(\"=\"*70)\n",
    "    logger.info(\"CUSTOM FILTERING PIPELINE\")\n",
    "    logger.info(\"=\"*70)\n",
    "    logger.info(f\"Criteria:\")\n",
    "    logger.info(f\"  - Minimum companies: {min_companies}\")\n",
    "    logger.info(f\"  - Minimum skills: {min_skills}\")\n",
    "    logger.info(f\"  - Minimum positions: {min_positions}\")\n",
    "    logger.info(f\"  - Require location: {require_location}\")\n",
    "    logger.info(f\"  - Require salary: {require_salary}\")\n",
    "    logger.info(f\"  - Minimum words: {min_word_count}\")\n",
    "    logger.info(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    df = pd.read_csv(input_csv)\n",
    "    original_count = len(df)\n",
    "    \n",
    "    # Count features\n",
    "    df['company_count'] = df['companies_extracted'].fillna('').apply(lambda x: len([c for c in str(x).split(',') if c.strip()]))\n",
    "    df['skill_count'] = df['skills_extracted'].fillna('').apply(lambda x: len([s for s in str(x).split(',') if s.strip()]))\n",
    "    df['position_count'] = df['positions_extracted'].fillna('').apply(lambda x: len([p for p in str(x).split(',') if p.strip()]))\n",
    "    df['has_location'] = df['locations_extracted'].fillna('').apply(lambda x: len(str(x).strip()) > 0)\n",
    "    df['has_salary'] = df['salary_info'].fillna('').apply(lambda x: len(str(x).strip()) > 0)\n",
    "    df['word_count'] = df['cleaned_text'].fillna('').apply(lambda x: len(str(x).split()))\n",
    "    \n",
    "    # Apply filters\n",
    "    mask = (\n",
    "        (df['company_count'] >= min_companies) &\n",
    "        (df['skill_count'] >= min_skills) &\n",
    "        (df['position_count'] >= min_positions) &\n",
    "        (df['word_count'] >= min_word_count)\n",
    "    )\n",
    "    \n",
    "    if require_location:\n",
    "        mask = mask & df['has_location']\n",
    "    \n",
    "    if require_salary:\n",
    "        mask = mask & df['has_salary']\n",
    "    \n",
    "    filtered_df = df[mask].copy()\n",
    "    \n",
    "    # Select columns\n",
    "    existing_columns = [col for col in FINAL_COLUMNS if col in df.columns]\n",
    "    filtered_df = filtered_df[existing_columns]\n",
    "    \n",
    "    # Save\n",
    "    filtered_df.to_csv(output_csv, index=False)\n",
    "    \n",
    "    logger.info(f\"Filtered {len(filtered_df)}/{original_count} emails\")\n",
    "    logger.info(f\"Saved to: {output_csv}\\n\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# ===================================================================\n",
    "# QUALITY ANALYSIS\n",
    "# ===================================================================\n",
    "\n",
    "def analyze_data_quality(csv_path: str):\n",
    "    \"\"\"Analyze quality of extracted data.\"\"\"\n",
    "    \n",
    "    logger.info(\"=\"*70)\n",
    "    logger.info(\"DATA QUALITY ANALYSIS\")\n",
    "    logger.info(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    logger.info(f\"Total Emails: {len(df)}\")\n",
    "    logger.info(f\"\\nColumn Completeness:\")\n",
    "    \n",
    "    for col in ['companies_extracted', 'skills_extracted', 'positions_extracted', \n",
    "                'locations_extracted', 'salary_info', 'experience_required', 'degrees_required']:\n",
    "        if col in df.columns:\n",
    "            non_empty = df[col].notna() & (df[col] != '')\n",
    "            count = non_empty.sum()\n",
    "            percentage = (count / len(df)) * 100\n",
    "            logger.info(f\"  {col}: {count} ({percentage:.1f}%)\")\n",
    "    \n",
    "    logger.info(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# ===================================================================\n",
    "# MAIN EXECUTION\n",
    "# ===================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Option 1: Standard filtering (recommended)\n",
    "    logger.info(\"OPTION 1: STANDARD FILTERING\")\n",
    "    logger.info(\"Keep emails with at least 2 features extracted\\n\")\n",
    "    \n",
    "    filtered_df = filter_relevant_emails(\n",
    "        input_csv=\"ai_cleaned_emails.csv\",\n",
    "        output_csv=\"relevant_placement_emails.csv\"\n",
    "    )\n",
    "    \n",
    "    # Option 2: Custom filtering (if you need specific criteria)\n",
    "    # Uncomment and modify as needed:\n",
    "    \n",
    "    # logger.info(\"\\nðŸ”µ OPTION 2: CUSTOM FILTERING\")\n",
    "    # logger.info(\"Keep emails with specific requirements\\n\")\n",
    "    # \n",
    "    # custom_df = filter_by_custom_criteria(\n",
    "    #     input_csv=\"ai_cleaned_emails.csv\",\n",
    "    #     output_csv=\"custom_placement_emails.csv\",\n",
    "    #     min_companies=1,      # Must have at least 1 company\n",
    "    #     min_skills=2,         # Must have at least 2 skills\n",
    "    #     min_positions=1,      # Must have at least 1 position\n",
    "    #     require_location=True, # Must have location\n",
    "    #     require_salary=False,  # Salary optional\n",
    "    #     min_word_count=30     # At least 30 words\n",
    "    # )\n",
    "    \n",
    "    # Option 3: Quality analysis\n",
    "    logger.info(\"\\nANALYZING DATA QUALITY\")\n",
    "    analyze_data_quality(\"relevant_placement_emails.csv\")\n",
    "    \n",
    "    logger.info(\"All filtering operations complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Placement Mail Analysis System",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
