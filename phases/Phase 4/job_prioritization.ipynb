{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c998116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# PHASE 4: SMART JOB PRIORITIZATION ENGINE\n",
    "# Production-Level Code with ML-based Scoring and User Customization\n",
    "# ===================================================================\n",
    "# Purpose: Automatically prioritize job postings based on user profile\n",
    "#          and preferences with optional user customization\n",
    "# ===================================================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Optional, Tuple, Set\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Import config loader\n",
    "try:\n",
    "    from config_loader import (\n",
    "        load_config,\n",
    "        create_user_profile_from_config,\n",
    "        create_weights_from_config,\n",
    "        get_input_output_paths,\n",
    "        get_incremental_processing_config,\n",
    "        get_company_reputation_config,\n",
    "        get_skills_scoring_config,\n",
    "        get_location_scoring_config,\n",
    "        get_salary_scoring_config,\n",
    "        get_deadline_urgency_config,\n",
    "        get_logging_config\n",
    "    )\n",
    "    CONFIG_LOADER_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"Warning: config_loader.py not found. Using defaults.\")\n",
    "    CONFIG_LOADER_AVAILABLE = False\n",
    "\n",
    "# ===================================================================\n",
    "# GLOBAL CONFIG INITIALIZATION\n",
    "# ===================================================================\n",
    "\n",
    "if CONFIG_LOADER_AVAILABLE:\n",
    "    try:\n",
    "        config = load_config(\"config.json\")\n",
    "        user_profile_data = create_user_profile_from_config(config)\n",
    "        weights_data = create_weights_from_config(config)\n",
    "        paths_config = get_input_output_paths(config)\n",
    "        incremental_config = get_incremental_processing_config(config)\n",
    "        company_rep_config = get_company_reputation_config(config)\n",
    "        skills_config = get_skills_scoring_config(config)\n",
    "        location_config = get_location_scoring_config(config)\n",
    "        salary_config = get_salary_scoring_config(config)\n",
    "        deadline_config = get_deadline_urgency_config(config)\n",
    "        logging_config = get_logging_config(config)\n",
    "        CONFIG_LOADED = True\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not load config.json: {e}\")\n",
    "        CONFIG_LOADED = False\n",
    "else:\n",
    "    CONFIG_LOADED = False\n",
    "\n",
    "# Default configuration if config not loaded\n",
    "if not CONFIG_LOADED:\n",
    "    config = {}\n",
    "    user_profile_data = {\n",
    "        'user_id': 'USER_001',\n",
    "        'name': 'Sample User',\n",
    "        'skills': ['python', 'machine learning', 'sql'],\n",
    "        'primary_skills': ['python', 'machine learning'],\n",
    "        'education': ['B.Tech'],\n",
    "        'experience_years': 0.0,\n",
    "        'preferred_locations': ['Bangalore', 'Remote'],\n",
    "        'preferred_companies': [],\n",
    "        'preferred_work_mode': 'Remote',\n",
    "        'min_expected_salary': 300000,\n",
    "        'max_expected_salary': 800000,\n",
    "        'must_have_skills': ['python'],\n",
    "        'avoid_keywords': []\n",
    "    }\n",
    "    weights_data = {\n",
    "        'skills_match_weight': 0.30,\n",
    "        'experience_match_weight': 0.05,\n",
    "        'education_match_weight': 0.05,\n",
    "        'location_match_weight': 0.15,\n",
    "        'completeness_weight': 0.05,\n",
    "        'salary_competitiveness_weight': 0.15,\n",
    "        'company_reputation_weight': 0.10,\n",
    "        'deadline_urgency_weight': 0.10,\n",
    "        'posting_freshness_weight': 0.05,\n",
    "        'preference_bonus_weight': 0.10\n",
    "    }\n",
    "    paths_config = {\n",
    "        'input_file': '../Phase 3/structured_job_postings.json',\n",
    "        'output_csv': 'prioritized_jobs.csv',\n",
    "        'top_recommendations_csv': 'top_recommendations.csv',\n",
    "        'top_n': 20\n",
    "    }\n",
    "    incremental_config = {\n",
    "        'enabled': False,\n",
    "        'state_directory': 'state',\n",
    "        'state_file': 'prioritized_job_ids.txt',\n",
    "        'force_full_reprocess': False\n",
    "    }\n",
    "    company_rep_config = {\n",
    "        'tier_scores': {'faang': 1.0, 'unicorn': 0.95, 'mnc': 0.85, 'unknown': 0.5},\n",
    "        'faang_companies': {'google', 'microsoft', 'amazon', 'apple', 'meta', 'facebook', 'netflix'},\n",
    "        'unicorn_companies': {'flipkart', 'swiggy', 'zomato', 'paytm'},\n",
    "        'mnc_companies': {'ibm', 'oracle', 'sap', 'cisco', 'intel', 'nvidia', 'adobe'}\n",
    "    }\n",
    "    location_config = {\n",
    "        'exact_match_score': 1.0,\n",
    "        'remote_score': 1.0,\n",
    "        'tier1_cities_score': 0.8,\n",
    "        'tier2_cities_score': 0.6,\n",
    "        'other_cities_score': 0.4,\n",
    "        'tier1_cities': {'bangalore', 'mumbai', 'delhi', 'hyderabad', 'pune', 'chennai'},\n",
    "        'tier2_cities': {'kolkata', 'ahmedabad', 'gurgaon', 'noida'}\n",
    "    }\n",
    "    salary_config = {\n",
    "        'ideal_salary_lpa': 8.0,\n",
    "        'min_acceptable_lpa': 3.0,\n",
    "        'max_expected_lpa': 15.0,\n",
    "        'below_min_penalty': 0.5,\n",
    "        'above_max_bonus': 0.2,\n",
    "        'missing_salary_score': 0.5\n",
    "    }\n",
    "    deadline_config = {\n",
    "        'days_thresholds': {'urgent': 3, 'soon': 7, 'moderate': 14, 'relaxed': 30},\n",
    "        'urgency_scores': {'urgent': 1.0, 'soon': 0.9, 'moderate': 0.7, 'relaxed': 0.5, 'no_deadline': 0.3},\n",
    "        'expired_penalty': 0.0\n",
    "    }\n",
    "    logging_config = {'level': 'INFO', 'file': 'job_prioritization.log'}\n",
    "\n",
    "# ===================================================================\n",
    "# LOGGING CONFIGURATION\n",
    "# ===================================================================\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=getattr(logging, logging_config['level']),\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(logging_config['file'], encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(\"JobPrioritization\")\n",
    "\n",
    "# ===================================================================\n",
    "# USER PROFILE DATA CLASS\n",
    "# ===================================================================\n",
    "\n",
    "@dataclass\n",
    "class UserProfile:\n",
    "    \"\"\"User profile containing skills, preferences, and requirements.\"\"\"\n",
    "    \n",
    "    user_id: str\n",
    "    name: str\n",
    "    skills: List[str] = field(default_factory=list)\n",
    "    primary_skills: List[str] = field(default_factory=list)\n",
    "    education: List[str] = field(default_factory=list)\n",
    "    experience_years: float = 0.0\n",
    "    preferred_locations: List[str] = field(default_factory=list)\n",
    "    preferred_companies: List[str] = field(default_factory=list)\n",
    "    preferred_work_mode: str = \"Any\"\n",
    "    min_expected_salary: float = 0.0\n",
    "    max_expected_salary: float = float('inf')\n",
    "    must_have_skills: List[str] = field(default_factory=list)\n",
    "    avoid_keywords: List[str] = field(default_factory=list)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config: Dict) -> 'UserProfile':\n",
    "        \"\"\"Create UserProfile from config dictionary.\"\"\"\n",
    "        if CONFIG_LOADER_AVAILABLE:\n",
    "            user_data = create_user_profile_from_config(config)\n",
    "        else:\n",
    "            user_data = user_profile_data\n",
    "        return cls(**user_data)\n",
    "    \n",
    "    @classmethod\n",
    "    def create_sample_profile(cls) -> 'UserProfile':\n",
    "        \"\"\"Create a sample user profile for testing.\"\"\"\n",
    "        return cls(**user_profile_data)\n",
    "\n",
    "# ===================================================================\n",
    "# PRIORITIZATION WEIGHTS CONFIGURATION\n",
    "# ===================================================================\n",
    "\n",
    "@dataclass\n",
    "class PrioritizationWeights:\n",
    "    \"\"\"Configurable weights for job prioritization scoring.\"\"\"\n",
    "    \n",
    "    skills_match_weight: float = 0.30\n",
    "    experience_match_weight: float = 0.05\n",
    "    education_match_weight: float = 0.05\n",
    "    location_match_weight: float = 0.15\n",
    "    completeness_weight: float = 0.05\n",
    "    salary_competitiveness_weight: float = 0.15\n",
    "    company_reputation_weight: float = 0.10\n",
    "    deadline_urgency_weight: float = 0.10\n",
    "    posting_freshness_weight: float = 0.05\n",
    "    preference_bonus_weight: float = 0.10\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config: Dict) -> 'PrioritizationWeights':\n",
    "        \"\"\"Create PrioritizationWeights from config dictionary.\"\"\"\n",
    "        return cls(**weights_data)\n",
    "    \n",
    "    @classmethod\n",
    "    def get_default(cls) -> 'PrioritizationWeights':\n",
    "        \"\"\"Get default weights.\"\"\"\n",
    "        return cls()\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, float]:\n",
    "        \"\"\"Convert to dictionary.\"\"\"\n",
    "        return asdict(self)\n",
    "\n",
    "# ===================================================================\n",
    "# INCREMENTAL PROCESSING UTILITIES\n",
    "# ===================================================================\n",
    "\n",
    "def load_processed_job_ids(state_file: str) -> set:\n",
    "    \"\"\"Load already processed job IDs from state file.\"\"\"\n",
    "    if not os.path.exists(state_file):\n",
    "        return set()\n",
    "    \n",
    "    with open(state_file, 'r', encoding='utf-8') as f:\n",
    "        return set(line.strip() for line in f if line.strip())\n",
    "\n",
    "def save_processed_job_ids(state_file: str, job_ids: set):\n",
    "    \"\"\"Save processed job IDs to state file.\"\"\"\n",
    "    os.makedirs(os.path.dirname(state_file), exist_ok=True)\n",
    "    with open(state_file, 'w', encoding='utf-8') as f:\n",
    "        for job_id in sorted(job_ids):\n",
    "            f.write(f\"{job_id}\\n\")\n",
    "\n",
    "def get_new_jobs_to_process(jobs_df: pd.DataFrame, state_file: str, force_reprocess: bool = False):\n",
    "    \"\"\"\n",
    "    Filter jobs to only process new ones.\n",
    "    \n",
    "    Args:\n",
    "        jobs_df: DataFrame with all jobs\n",
    "        state_file: Path to state file\n",
    "        force_reprocess: If True, process all jobs\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (new_jobs_df, processed_ids)\n",
    "    \"\"\"\n",
    "    if force_reprocess:\n",
    "        logger.info(\"Force reprocess enabled - processing all jobs\")\n",
    "        return jobs_df, set()\n",
    "    \n",
    "    processed_ids = load_processed_job_ids(state_file)\n",
    "    \n",
    "    if not processed_ids:\n",
    "        logger.info(\"No previous state found - processing all jobs\")\n",
    "        return jobs_df, set()\n",
    "    \n",
    "    # Assume job_id column exists\n",
    "    if 'job_id' not in jobs_df.columns:\n",
    "        logger.warning(\"No job_id column found - processing all jobs\")\n",
    "        return jobs_df, set()\n",
    "    \n",
    "    new_jobs = jobs_df[~jobs_df['job_id'].isin(processed_ids)]\n",
    "    \n",
    "    logger.info(f\"Total jobs: {len(jobs_df)}\")\n",
    "    logger.info(f\"Already processed: {len(processed_ids)}\")\n",
    "    logger.info(f\"New jobs to process: {len(new_jobs)}\")\n",
    "    \n",
    "    return new_jobs, processed_ids\n",
    "\n",
    "# ===================================================================\n",
    "# JOB SCORER BASE CLASS\n",
    "# ===================================================================\n",
    "\n",
    "class JobScorer:\n",
    "    \"\"\"Base class for calculating individual scoring components.\"\"\"\n",
    "    \n",
    "    def __init__(self, user_profile: UserProfile):\n",
    "        \"\"\"Initialize scorer with user profile.\"\"\"\n",
    "        self.user = user_profile\n",
    "        self.logger = logging.getLogger(\"JobScorer\")\n",
    "    \n",
    "    def calculate_skills_match(self, job: pd.Series) -> float:\n",
    "        \"\"\"Calculate skills match score.\"\"\"\n",
    "        try:\n",
    "            job_skills_str = str(job.get('skills', '')).lower()\n",
    "            if not job_skills_str or job_skills_str == 'nan':\n",
    "                return 0.0\n",
    "            \n",
    "            # Count matching skills\n",
    "            matches = sum(1 for skill in self.user.primary_skills \n",
    "                         if skill.lower() in job_skills_str)\n",
    "            \n",
    "            if len(self.user.primary_skills) == 0:\n",
    "                return 0.5\n",
    "            \n",
    "            return min(matches / len(self.user.primary_skills), 1.0)\n",
    "        except:\n",
    "            return 0.0\n",
    "    \n",
    "    def calculate_experience_match(self, job: pd.Series) -> float:\n",
    "        \"\"\"Calculate experience match score.\"\"\"\n",
    "        try:\n",
    "            exp_str = str(job.get('experience_required', '')).lower()\n",
    "            \n",
    "            if 'fresher' in exp_str or 'entry' in exp_str:\n",
    "                return 1.0 if self.user.experience_years <= 2 else 0.8\n",
    "            \n",
    "            # Extract years\n",
    "            import re\n",
    "            years = re.findall(r'(\\d+)', exp_str)\n",
    "            if years:\n",
    "                required_exp = float(years[0])\n",
    "                if self.user.experience_years >= required_exp:\n",
    "                    return 1.0\n",
    "                elif self.user.experience_years >= required_exp * 0.7:\n",
    "                    return 0.8\n",
    "                else:\n",
    "                    return 0.5\n",
    "            \n",
    "            return 0.7\n",
    "        except:\n",
    "            return 0.7\n",
    "    \n",
    "    def calculate_education_match(self, job: pd.Series) -> float:\n",
    "        \"\"\"Calculate education match score.\"\"\"\n",
    "        try:\n",
    "            edu_str = str(job.get('education_required', '')).lower()\n",
    "            \n",
    "            if not edu_str or edu_str == 'nan':\n",
    "                return 0.8\n",
    "            \n",
    "            for user_edu in self.user.education:\n",
    "                if user_edu.lower() in edu_str:\n",
    "                    return 1.0\n",
    "            \n",
    "            return 0.6\n",
    "        except:\n",
    "            return 0.8\n",
    "    \n",
    "    def calculate_completeness_score(self, job: pd.Series) -> float:\n",
    "        \"\"\"Calculate data completeness score.\"\"\"\n",
    "        try:\n",
    "            required_fields = ['company_name', 'position', 'skills']\n",
    "            important_fields = ['location_city', 'salary_range', 'experience_required']\n",
    "            \n",
    "            required_score = sum(1 for f in required_fields if pd.notna(job.get(f))) / len(required_fields)\n",
    "            important_score = sum(1 for f in important_fields if pd.notna(job.get(f))) / len(important_fields)\n",
    "            \n",
    "            return 0.6 * required_score + 0.4 * important_score\n",
    "        except:\n",
    "            return 0.5\n",
    "    \n",
    "    def calculate_posting_freshness(self, job: pd.Series) -> float:\n",
    "        \"\"\"Calculate posting freshness score.\"\"\"\n",
    "        try:\n",
    "            timestamp_str = str(job.get('extraction_timestamp', ''))\n",
    "            \n",
    "            if not timestamp_str or timestamp_str.lower() == 'nan':\n",
    "                return 0.6\n",
    "            \n",
    "            posting_time = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))\n",
    "            posting_time_naive = posting_time.replace(tzinfo=None)\n",
    "            now_naive = datetime.now().replace(tzinfo=None)\n",
    "            days_old = (now_naive - posting_time_naive).days\n",
    "            \n",
    "            if days_old <= 3:\n",
    "                return 1.0\n",
    "            elif days_old <= 7:\n",
    "                return 0.8\n",
    "            elif days_old <= 14:\n",
    "                return 0.6\n",
    "            elif days_old <= 30:\n",
    "                return 0.4\n",
    "            else:\n",
    "                return 0.2\n",
    "        except:\n",
    "            return 0.6\n",
    "    \n",
    "    def calculate_preference_bonus(self, job: pd.Series) -> float:\n",
    "        \"\"\"Calculate preference bonus score.\"\"\"\n",
    "        try:\n",
    "            bonus = 0.0\n",
    "            \n",
    "            company_name = str(job.get('company_name', ''))\n",
    "            if company_name in self.user.preferred_companies:\n",
    "                bonus += 0.4\n",
    "            \n",
    "            location = str(job.get('location_city', ''))\n",
    "            if location in self.user.preferred_locations:\n",
    "                bonus += 0.3\n",
    "            \n",
    "            work_mode = str(job.get('work_mode', ''))\n",
    "            if work_mode == self.user.preferred_work_mode or self.user.preferred_work_mode == 'Any':\n",
    "                bonus += 0.3\n",
    "            \n",
    "            return min(bonus, 1.0)\n",
    "        except:\n",
    "            return 0.0\n",
    "\n",
    "# Continue in next message due to length...\n",
    "\n",
    "# ===================================================================\n",
    "# CONFIGURABLE JOB SCORER (ENHANCED WITH CONFIG)\n",
    "# ===================================================================\n",
    "\n",
    "class ConfigurableJobScorer(JobScorer):\n",
    "    \"\"\"Enhanced JobScorer that uses configuration for scoring logic.\"\"\"\n",
    "    \n",
    "    def __init__(self, user_profile: UserProfile, config_dict: Dict):\n",
    "        super().__init__(user_profile)\n",
    "        self.config = config_dict\n",
    "        self.company_rep_config = company_rep_config\n",
    "        self.location_config = location_config\n",
    "        self.salary_config = salary_config\n",
    "        self.deadline_config = deadline_config\n",
    "    \n",
    "    def calculate_company_reputation(self, job: pd.Series) -> float:\n",
    "        \"\"\"Calculate company reputation using config-based company lists.\"\"\"\n",
    "        try:\n",
    "            company_name = str(job.get('company_name', '')).lower().strip()\n",
    "            \n",
    "            if not company_name or company_name == 'nan':\n",
    "                return self.company_rep_config['tier_scores'].get('unknown', 0.5)\n",
    "            \n",
    "            # Check FAANG\n",
    "            if any(faang in company_name for faang in self.company_rep_config['faang_companies']):\n",
    "                return self.company_rep_config['tier_scores'].get('faang', 1.0)\n",
    "            \n",
    "            # Check Unicorns\n",
    "            if any(unicorn in company_name for unicorn in self.company_rep_config['unicorn_companies']):\n",
    "                return self.company_rep_config['tier_scores'].get('unicorn', 0.95)\n",
    "            \n",
    "            # Check MNCs\n",
    "            if any(mnc in company_name for mnc in self.company_rep_config['mnc_companies']):\n",
    "                return self.company_rep_config['tier_scores'].get('mnc', 0.85)\n",
    "            \n",
    "            return self.company_rep_config['tier_scores'].get('unknown', 0.5)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating company reputation: {e}\")\n",
    "            return 0.5\n",
    "    \n",
    "    def calculate_location_match(self, job: pd.Series) -> float:\n",
    "        \"\"\"Calculate location match using config-based tier scoring.\"\"\"\n",
    "        try:\n",
    "            location = str(job.get('location_city', '')).lower().strip()\n",
    "            \n",
    "            if not location or location == 'nan':\n",
    "                return 0.5\n",
    "            \n",
    "            # Check if it's a preferred location\n",
    "            if location in [loc.lower() for loc in self.user.preferred_locations]:\n",
    "                return self.location_config['exact_match_score']\n",
    "            \n",
    "            # Check for remote\n",
    "            if 'remote' in location or 'wfh' in location:\n",
    "                return self.location_config['remote_score']\n",
    "            \n",
    "            # Check tier 1 cities\n",
    "            if location in self.location_config['tier1_cities']:\n",
    "                return self.location_config['tier1_cities_score']\n",
    "            \n",
    "            # Check tier 2 cities\n",
    "            if location in self.location_config['tier2_cities']:\n",
    "                return self.location_config['tier2_cities_score']\n",
    "            \n",
    "            return self.location_config['other_cities_score']\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating location match: {e}\")\n",
    "            return 0.5\n",
    "    \n",
    "    def calculate_salary_competitiveness(self, job: pd.Series) -> float:\n",
    "        \"\"\"Calculate salary competitiveness using config-based thresholds.\"\"\"\n",
    "        try:\n",
    "            salary_str = str(job.get('salary_range', ''))\n",
    "            \n",
    "            if not salary_str or salary_str == 'nan':\n",
    "                return self.salary_config['missing_salary_score']\n",
    "            \n",
    "            # Extract salary (assuming LPA format)\n",
    "            salary_match = re.search(r'(\\d+(?:\\.\\d+)?)', salary_str)\n",
    "            \n",
    "            if not salary_match:\n",
    "                return self.salary_config['missing_salary_score']\n",
    "            \n",
    "            salary_lpa = float(salary_match.group(1))\n",
    "            \n",
    "            ideal = self.salary_config['ideal_salary_lpa']\n",
    "            min_acceptable = self.salary_config['min_acceptable_lpa']\n",
    "            max_expected = self.salary_config['max_expected_lpa']\n",
    "            \n",
    "            if salary_lpa < min_acceptable:\n",
    "                return self.salary_config['below_min_penalty']\n",
    "            elif salary_lpa > max_expected:\n",
    "                return min(1.0 + self.salary_config['above_max_bonus'], 1.0)\n",
    "            else:\n",
    "                # Linear interpolation\n",
    "                if salary_lpa <= ideal:\n",
    "                    return 0.5 + 0.5 * (salary_lpa - min_acceptable) / (ideal - min_acceptable)\n",
    "                else:\n",
    "                    return 1.0\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating salary competitiveness: {e}\")\n",
    "            return 0.5\n",
    "    \n",
    "    def calculate_deadline_urgency(self, job: pd.Series) -> float:\n",
    "        \"\"\"Calculate deadline urgency using config-based thresholds.\"\"\"\n",
    "        try:\n",
    "            deadline_str = str(job.get('application_deadline', ''))\n",
    "            \n",
    "            if not deadline_str or deadline_str == 'nan' or deadline_str == 'None':\n",
    "                return self.deadline_config['urgency_scores'].get('no_deadline', 0.3)\n",
    "            \n",
    "            try:\n",
    "                deadline = datetime.strptime(deadline_str, '%Y-%m-%d')\n",
    "                days_remaining = (deadline - datetime.now()).days\n",
    "                \n",
    "                if days_remaining < 0:\n",
    "                    return self.deadline_config['expired_penalty']\n",
    "                \n",
    "                thresholds = self.deadline_config['days_thresholds']\n",
    "                scores = self.deadline_config['urgency_scores']\n",
    "                \n",
    "                if days_remaining <= thresholds.get('urgent', 3):\n",
    "                    return scores.get('urgent', 1.0)\n",
    "                elif days_remaining <= thresholds.get('soon', 7):\n",
    "                    return scores.get('soon', 0.9)\n",
    "                elif days_remaining <= thresholds.get('moderate', 14):\n",
    "                    return scores.get('moderate', 0.7)\n",
    "                elif days_remaining <= thresholds.get('relaxed', 30):\n",
    "                    return scores.get('relaxed', 0.5)\n",
    "                else:\n",
    "                    return scores.get('no_deadline', 0.3)\n",
    "                    \n",
    "            except:\n",
    "                return self.deadline_config['urgency_scores'].get('no_deadline', 0.3)\n",
    "                \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating deadline urgency: {e}\")\n",
    "            return 0.5\n",
    "\n",
    "# ===================================================================\n",
    "# SMART PRIORITIZATION ENGINE\n",
    "# ===================================================================\n",
    "\n",
    "class SmartPrioritizationEngine:\n",
    "    \"\"\"Main prioritization engine that orchestrates scoring and ranking.\"\"\"\n",
    "    \n",
    "    def __init__(self, user_profile: UserProfile, weights: Optional[PrioritizationWeights] = None):\n",
    "        \"\"\"Initialize prioritization engine.\"\"\"\n",
    "        self.user_profile = user_profile\n",
    "        self.weights = weights or PrioritizationWeights.get_default()\n",
    "        self.scorer = ConfigurableJobScorer(user_profile, config)\n",
    "        self.logger = logging.getLogger(\"PrioritizationEngine\")\n",
    "        \n",
    "        self.logger.info(\"=\"*70)\n",
    "        self.logger.info(\"SMART PRIORITIZATION ENGINE INITIALIZED\")\n",
    "        self.logger.info(\"=\"*70)\n",
    "        self.logger.info(f\"User: {user_profile.name} ({user_profile.user_id})\")\n",
    "        self.logger.info(f\"Skills: {', '.join(user_profile.primary_skills[:5])}\")\n",
    "        self.logger.info(f\"Experience: {user_profile.experience_years} years\")\n",
    "        self.logger.info(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    def calculate_job_priority(self, job: pd.Series) -> Dict[str, float]:\n",
    "        \"\"\"Calculate comprehensive priority score for a job.\"\"\"\n",
    "        try:\n",
    "            # Calculate all scoring components\n",
    "            scores = {\n",
    "                'skills_match': self.scorer.calculate_skills_match(job),\n",
    "                'experience_match': self.scorer.calculate_experience_match(job),\n",
    "                'education_match': self.scorer.calculate_education_match(job),\n",
    "                'location_match': self.scorer.calculate_location_match(job),\n",
    "                'completeness': self.scorer.calculate_completeness_score(job),\n",
    "                'salary_competitiveness': self.scorer.calculate_salary_competitiveness(job),\n",
    "                'company_reputation': self.scorer.calculate_company_reputation(job),\n",
    "                'deadline_urgency': self.scorer.calculate_deadline_urgency(job),\n",
    "                'posting_freshness': self.scorer.calculate_posting_freshness(job),\n",
    "                'preference_bonus': self.scorer.calculate_preference_bonus(job)\n",
    "            }\n",
    "            \n",
    "            # Calculate weighted total (0-1 scale)\n",
    "            final_score = (\n",
    "                scores['skills_match'] * self.weights.skills_match_weight +\n",
    "                scores['experience_match'] * self.weights.experience_match_weight +\n",
    "                scores['education_match'] * self.weights.education_match_weight +\n",
    "                scores['location_match'] * self.weights.location_match_weight +\n",
    "                scores['completeness'] * self.weights.completeness_weight +\n",
    "                scores['salary_competitiveness'] * self.weights.salary_competitiveness_weight +\n",
    "                scores['company_reputation'] * self.weights.company_reputation_weight +\n",
    "                scores['deadline_urgency'] * self.weights.deadline_urgency_weight +\n",
    "                scores['posting_freshness'] * self.weights.posting_freshness_weight +\n",
    "                scores['preference_bonus'] * self.weights.preference_bonus_weight\n",
    "            )\n",
    "            \n",
    "            # Scale to 0-100\n",
    "            scores['final_priority_score'] = final_score * 100\n",
    "            scores['priority_tier'] = self._get_priority_tier(scores['final_priority_score'])\n",
    "            \n",
    "            return scores\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error calculating job priority: {e}\")\n",
    "            return {'final_priority_score': 0.0, 'priority_tier': 'Error'}\n",
    "    \n",
    "    def _get_priority_tier(self, score: float) -> str:\n",
    "        \"\"\"Get priority tier based on score.\"\"\"\n",
    "        if score >= 80:\n",
    "            return \"Highly Recommended\"\n",
    "        elif score >= 65:\n",
    "            return \"Recommended\"\n",
    "        elif score >= 50:\n",
    "            return \"Consider\"\n",
    "        else:\n",
    "            return \"Not Recommended\"\n",
    "    \n",
    "    def prioritize_jobs(self, jobs_df: pd.DataFrame, save_output: bool = True, \n",
    "                       output_path: str = \"prioritized_jobs.csv\") -> pd.DataFrame:\n",
    "        \"\"\"Prioritize all jobs in the DataFrame.\"\"\"\n",
    "        self.logger.info(f\"Prioritizing {len(jobs_df)} job postings...\")\n",
    "        \n",
    "        # Calculate scores for each job\n",
    "        results = []\n",
    "        for idx, job in jobs_df.iterrows():\n",
    "            scores = self.calculate_job_priority(job)\n",
    "            result = job.to_dict()\n",
    "            result.update(scores)\n",
    "            results.append(result)\n",
    "            \n",
    "            if (idx + 1) % 50 == 0:\n",
    "                self.logger.info(f\"   Processed {idx + 1}/{len(jobs_df)} jobs\")\n",
    "        \n",
    "        # Create result DataFrame\n",
    "        result_df = pd.DataFrame(results)\n",
    "        result_df = result_df.sort_values('final_priority_score', ascending=False)\n",
    "        \n",
    "        # Save if requested\n",
    "        if save_output:\n",
    "            result_df.to_csv(output_path, index=False)\n",
    "            self.logger.info(f\"Saved prioritized jobs to: {output_path}\")\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def get_recommended_jobs(self, df: pd.DataFrame, min_score: float = 65.0, \n",
    "                            max_results: int = 20) -> pd.DataFrame:\n",
    "        \"\"\"Get top recommended jobs.\"\"\"\n",
    "        recommended = df[df['final_priority_score'] >= min_score]\n",
    "        return recommended.head(max_results)\n",
    "\n",
    "# ===================================================================\n",
    "# MAIN EXECUTION WITH CONFIG\n",
    "# ===================================================================\n",
    "\n",
    "def main_with_config():\n",
    "    \"\"\"Main execution function using config.json settings.\"\"\"\n",
    "    logger.info(\"\\n\" + \"=\"*70)\n",
    "    logger.info(\"STARTING JOB PRIORITIZATION WITH CONFIG\")\n",
    "    logger.info(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Get input file path\n",
    "        input_file = paths_config['input_file']\n",
    "        \n",
    "        # Convert to absolute path if relative\n",
    "        if not os.path.isabs(input_file):\n",
    "            current_dir = os.getcwd()\n",
    "            input_file = os.path.join(current_dir, input_file)\n",
    "        \n",
    "        logger.info(f\"Loading jobs from: {input_file}\")\n",
    "        \n",
    "        # Load jobs (support both CSV and JSON)\n",
    "        if input_file.endswith('.json'):\n",
    "            with open(input_file, 'r', encoding='utf-8') as f:\n",
    "                jobs_data = json.load(f)\n",
    "            jobs_df = pd.DataFrame(jobs_data)\n",
    "        else:\n",
    "            jobs_df = pd.read_csv(input_file)\n",
    "        \n",
    "        logger.info(f\"Loaded {len(jobs_df)} job postings\\n\")\n",
    "        \n",
    "        # Incremental processing\n",
    "        if incremental_config['enabled']:\n",
    "            state_dir = incremental_config['state_directory']\n",
    "            state_file = os.path.join(state_dir, incremental_config['state_file'])\n",
    "            \n",
    "            new_jobs_df, processed_ids = get_new_jobs_to_process(\n",
    "                jobs_df,\n",
    "                state_file,\n",
    "                incremental_config['force_full_reprocess']\n",
    "            )\n",
    "            \n",
    "            if len(new_jobs_df) == 0:\n",
    "                logger.info(\"No new jobs to process!\")\n",
    "                return None, None\n",
    "            \n",
    "            jobs_to_process = new_jobs_df\n",
    "        else:\n",
    "            jobs_to_process = jobs_df\n",
    "            processed_ids = set()\n",
    "        \n",
    "        # Create user profile from config\n",
    "        user_profile = UserProfile(**user_profile_data)\n",
    "        \n",
    "        # Create weights from config\n",
    "        weights = PrioritizationWeights(**weights_data)\n",
    "        \n",
    "        # Initialize engine\n",
    "        engine = SmartPrioritizationEngine(\n",
    "            user_profile=user_profile,\n",
    "            weights=weights\n",
    "        )\n",
    "        \n",
    "        # Prioritize jobs\n",
    "        prioritized_df = engine.prioritize_jobs(\n",
    "            jobs_df=jobs_to_process,\n",
    "            save_output=True,\n",
    "            output_path=paths_config['output_csv']\n",
    "        )\n",
    "        \n",
    "        # If incremental, merge with existing results\n",
    "        if incremental_config['enabled'] and len(processed_ids) > 0:\n",
    "            existing_file = paths_config['output_csv']\n",
    "            if os.path.exists(existing_file):\n",
    "                existing_df = pd.read_csv(existing_file)\n",
    "                prioritized_df = pd.concat([existing_df, prioritized_df], ignore_index=True)\n",
    "                prioritized_df = prioritized_df.sort_values('final_priority_score', ascending=False)\n",
    "                prioritized_df.to_csv(existing_file, index=False)\n",
    "                logger.info(f\"Merged with existing results\")\n",
    "        \n",
    "        # Update state file\n",
    "        if incremental_config['enabled'] and 'job_id' in prioritized_df.columns:\n",
    "            new_processed_ids = set(prioritized_df['job_id'].astype(str))\n",
    "            all_processed_ids = processed_ids.union(new_processed_ids)\n",
    "            save_processed_job_ids(state_file, all_processed_ids)\n",
    "            logger.info(f\"Updated state file: {len(all_processed_ids)} total processed jobs\")\n",
    "        \n",
    "        # Get top recommendations\n",
    "        top_n = paths_config['top_n']\n",
    "        recommendations = engine.get_recommended_jobs(\n",
    "            df=prioritized_df,\n",
    "            min_score=0.0,\n",
    "            max_results=top_n\n",
    "        )\n",
    "        \n",
    "        # Save recommendations\n",
    "        recommendations.to_csv(paths_config['top_recommendations_csv'], index=False)\n",
    "        logger.info(f\"Saved top {len(recommendations)} recommendations\\n\")\n",
    "        \n",
    "        logger.info(\"=\"*70)\n",
    "        logger.info(\"PRIORITIZATION COMPLETED\")\n",
    "        logger.info(\"=\"*70)\n",
    "        \n",
    "        return prioritized_df, engine\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"PIPELINE FAILED: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "# ===================================================================\n",
    "# ENTRY POINT\n",
    "# ===================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"PHASE 4: JOB PRIORITIZATION ENGINE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Config loaded: {CONFIG_LOADED}\")\n",
    "    print(f\"Config loader available: {CONFIG_LOADER_AVAILABLE}\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "    \n",
    "    # Run the pipeline\n",
    "    prioritized_df, engine = main_with_config()\n",
    "    \n",
    "    # Display top 10 results\n",
    "    if prioritized_df is not None:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"TOP 10 RECOMMENDATIONS\")\n",
    "        print(\"=\"*70 + \"\\n\")\n",
    "        \n",
    "        top_10 = prioritized_df.head(10)\n",
    "        \n",
    "        for idx, (_, job) in enumerate(top_10.iterrows(), 1):\n",
    "            print(f\"#{idx} | Score: {job['final_priority_score']:.1f}/100 | {job.get('priority_tier', 'N/A')}\")\n",
    "            print(f\"   Position: {job.get('position', 'N/A')}\")\n",
    "            print(f\"   Company: {job.get('company_name', 'N/A')}\")\n",
    "            print(f\"   Location: {job.get('location_city', 'N/A')}\")\n",
    "            \n",
    "            # Display skills (truncated)\n",
    "            skills = str(job.get('skills', 'N/A'))\n",
    "            if len(skills) > 60:\n",
    "                skills = skills[:60] + \"...\"\n",
    "            print(f\"   Skills: {skills}\")\n",
    "            \n",
    "            # Display salary if available\n",
    "            if 'salary_range' in job and pd.notna(job['salary_range']):\n",
    "                print(f\"   Salary: {job['salary_range']}\")\n",
    "            \n",
    "            print()\n",
    "        \n",
    "        print(\"=\"*70)\n",
    "        print(f\"Total jobs processed: {len(prioritized_df)}\")\n",
    "        print(f\"Output saved to: {paths_config['output_csv']}\")\n",
    "        print(f\"Top recommendations saved to: {paths_config['top_recommendations_csv']}\")\n",
    "        print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Placement Mail Analysis System",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
